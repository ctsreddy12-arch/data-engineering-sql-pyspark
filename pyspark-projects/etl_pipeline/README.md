### PySpark ETL Pipeline

This project demonstrates a simple ETL pipeline using PySpark.

Steps:
1. Read raw CSV data
2. Clean and validate records
3. Perform aggregations
4. Write processed data in Parquet format

Technologies:
- PySpark
- Spark DataFrame API
